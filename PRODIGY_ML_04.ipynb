{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a937c43f",
   "metadata": {},
   "source": [
    "# PRODIGY_ML_04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c3ddf",
   "metadata": {},
   "source": [
    "Develop a hand gesture recognition model in macihne learning that can accurately identify and classify different hand gestures from image or video data, enabling intuitive human-computer interaction and gesture-based control systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a2f24",
   "metadata": {},
   "source": [
    "### Libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71a6f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17337e",
   "metadata": {},
   "source": [
    "### Dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5be2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\KARTHIK\\OneDrive\\Desktop\\ALL FILES\\RESUME\\train\\train'\n",
    "test_dir = r'C:\\Users\\KARTHIK\\OneDrive\\Desktop\\ALL FILES\\RESUME\\test\\test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99721450",
   "metadata": {},
   "source": [
    "### Preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e6781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe57954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18000 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff87d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1f1d3",
   "metadata": {},
   "source": [
    "### Modeling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce5badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8227ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "562/562 [==============================] - 174s 305ms/step - loss: 0.7945 - accuracy: 0.7380 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "562/562 [==============================] - 67s 119ms/step - loss: 0.2180 - accuracy: 0.9265 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
      "Epoch 3/50\n",
      "562/562 [==============================] - 142s 252ms/step - loss: 0.1491 - accuracy: 0.9502 - val_loss: 0.0074 - val_accuracy: 0.9988\n",
      "Epoch 4/50\n",
      "562/562 [==============================] - 173s 307ms/step - loss: 0.1203 - accuracy: 0.9600 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "562/562 [==============================] - 70s 124ms/step - loss: 0.0906 - accuracy: 0.9692 - val_loss: 6.0253e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "562/562 [==============================] - 70s 124ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 7/50\n",
      "562/562 [==============================] - 69s 122ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 8/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0644 - accuracy: 0.9802 - val_loss: 3.9073e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 3.2166e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "562/562 [==============================] - 69s 123ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 3.9895e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "562/562 [==============================] - 72s 127ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 1.3064e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "562/562 [==============================] - 69s 123ms/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 3.3745e-04 - val_accuracy: 0.9998\n",
      "Epoch 13/50\n",
      "562/562 [==============================] - 68s 122ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 2.6690e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "562/562 [==============================] - 69s 123ms/step - loss: 0.0411 - accuracy: 0.9868 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 15/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 5.6215e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 2.3312e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "562/562 [==============================] - 137s 243ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 7.5437e-04 - val_accuracy: 0.9998\n",
      "Epoch 18/50\n",
      "562/562 [==============================] - 139s 247ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 4.1444e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "562/562 [==============================] - 137s 243ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 2.5152e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "562/562 [==============================] - 143s 254ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 5.7243e-04 - val_accuracy: 0.9998\n",
      "Epoch 21/50\n",
      "562/562 [==============================] - 146s 259ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 3.0064e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "562/562 [==============================] - 139s 248ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 5.8814e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "562/562 [==============================] - 139s 247ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 1.5322e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "562/562 [==============================] - 140s 248ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 1.3291e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "562/562 [==============================] - 139s 248ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 1.3870e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "562/562 [==============================] - 132s 234ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 8.3730e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "562/562 [==============================] - 70s 124ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 9.6543e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 2.8718e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "562/562 [==============================] - 68s 120ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 6.2641e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 6.6823e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 3.8172e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 33/50\n",
      "562/562 [==============================] - 68s 121ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 9.6020e-04 - val_accuracy: 0.9997\n",
      "Epoch 34/50\n",
      "562/562 [==============================] - 69s 123ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 7.2524e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "562/562 [==============================] - 69s 123ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 2.0110e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "562/562 [==============================] - 69s 122ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 4.9418e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "562/562 [==============================] - 84s 149ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 2.9403e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "562/562 [==============================] - 138s 245ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 2.3546e-04 - val_accuracy: 0.9998\n",
      "Epoch 39/50\n",
      "562/562 [==============================] - 140s 248ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 3.6435e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "562/562 [==============================] - 140s 249ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 2.2363e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "562/562 [==============================] - 158s 282ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 2.4423e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "562/562 [==============================] - 148s 263ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 8.1924e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "562/562 [==============================] - 144s 256ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 5.7068e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "562/562 [==============================] - 141s 250ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 8.8781e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "562/562 [==============================] - 144s 256ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 3.7596e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "562/562 [==============================] - 142s 253ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 1.4257e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "562/562 [==============================] - 73s 129ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2546e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "562/562 [==============================] - 68s 122ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 5.7484e-04 - val_accuracy: 0.9995\n",
      "Epoch 49/50\n",
      "562/562 [==============================] - 69s 122ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 4.7951e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "562/562 [==============================] - 70s 124ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0020 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4997d1",
   "metadata": {},
   "source": [
    "### Testing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de1ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0020 - accuracy: 0.9988\n",
      "Test Accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b94cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hand_gesture_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a174e15",
   "metadata": {},
   "source": [
    "### Predict :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01d0336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('hand_gesture_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ce6c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = sorted(os.listdir(r'C:\\Users\\KARTHIK\\OneDrive\\Desktop\\ALL FILES\\RESUME\\train\\train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d11bd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found or unable to read: {img_path}\")\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = img / 255.0  # Normalize the image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eca48c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gesture(img_path, model):\n",
    "    \"\"\"\n",
    "    Predict the gesture from the image using the trained model.\n",
    "    \"\"\"\n",
    "    img = preprocess_image(img_path)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f978fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if image exists at: C:\\Users\\KARTHIK\\OneDrive\\Desktop\\ALL FILES\\RESUME\\test\\test\\3\\903.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "Predicted Gesture: 3\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\KARTHIK\\OneDrive\\Desktop\\ALL FILES\\RESUME\\test\\test\\3\\903.jpg\"  # Replace with the path to the user-provided image\n",
    "print(f\"Checking if image exists at: {image_path}\")\n",
    "\n",
    "predicted_gesture = predict_gesture(image_path, model)\n",
    "print(f'Predicted Gesture: {predicted_gesture}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
